**Từ Ra Lệnh Đến Tinh Chỉnh: Khiến AI "Giống Tôi" Hơn – Một Hành Trình Khám Phá Fine-tuning**

*Thứ Hai, ngày 23 tháng 12 năm 2024, bởi grapeot | 0 Bình luận | Prompt Engineering, Finetuning, AI, Tiếng Anh*

Bạn đã bao giờ nhận ra cái giọng điệu "rất AI", có phần máy móc và xa cách, trong cách các mô hình trí tuệ nhân tạo giao tiếp chưa? Để tôi minh họa: khi yêu cầu AI dịch một câu tiếng Trung, một người bình thường có lẽ sẽ diễn đạt tự nhiên rằng: "Chúng ta cần vài API để client gửi tác vụ và nhận ID theo dõi tiến độ." Nhưng AI lại trịnh trọng đáp: "Hệ thống sẽ cung cấp nhiều API riêng biệt nhằm hỗ trợ việc đệ trình tác vụ của máy khách và tạo ra các định danh tác vụ tương ứng cho mục đích giám sát tiến trình sau đó." Một cảm giác "lệch pha" không thể phủ nhận – như thể một vị lãnh đạo đang đọc diễn văn, trang trọng, quan liêu và đầy khoảng cách.

Đây là một khúc mắc mà tôi đã trăn trở, tìm kiếm lời giải đáp suốt một thời gian dài. Chừng nào "căn bệnh" này chưa được chữa trị, tôi khó lòng tận dụng AI một cách hiệu quả cho việc dịch thuật hay biên soạn bài viết – bởi người đọc sẽ ngay lập tức nhận ra dấu ấn phi nhân tạo. Việc điều chỉnh giọng điệu của AI sao cho gần gũi hơn với văn phong của chính mình, tưởng chừng đơn giản, nhưng khi bắt tay vào thực hiện, bạn sẽ thấm thía sự phức tạp đến không ngờ. Bài viết này, qua lăng kính của nỗ lực "cá nhân hóa giọng điệu AI", sẽ dẫn dắt bạn khám phá một công cụ mạnh mẽ nhưng cũng đầy thách thức: **fine-tuning (tinh chỉnh)**.

Chúng ta sẽ cùng nhau lần giở lại những thất bại ban đầu, để thấy rằng thách thức cốt lõi nằm ở việc làm sao để AI thực sự "thẩm thấu" những chỉ dẫn chi tiết và đặc thù. Tiếp đó, bài viết sẽ phân tích những kịch bản nào thực sự phù hợp với fine-tuning và những trường hợp nào thì không. Cuối cùng, chúng ta sẽ đào sâu vào một số bí quyết kỹ thuật then chốt, những viên ngọc quý cần thiết cho hành trình fine-tuning.

**Những Thất Bại Nối Tiếp: Hành Trình Tìm Kiếm Sự Đồng Điệu**

Hướng tiếp cận trực quan nhất để kiểm soát giọng điệu, dĩ nhiên, là **Prompt Engineering (Kỹ thuật Ra Lệnh)** – và đó cũng là thử nghiệm đầu tiên của tôi. Tuy nhiên, một rào cản lớn hiện hữu: làm thế nào để AI tìm được điểm cân bằng hoàn hảo? Nếu chỉ đơn thuần ra lệnh "hãy bớt trang trọng đi", AI thường trượt sang một thái cực khác hẳn. Nó bỗng trở nên quá xuồng xã, thậm chí bông đùa, một kết quả cũng chẳng hề mong muốn. Vậy, nút thắt nằm ở chỗ: làm sao để mô tả một cách tường minh cho AI biết chính xác vị trí mà chúng ta muốn nó "an tọa" giữa hai thái cực trang trọng và thân mật?

Sau những nỗ lực bất thành trong việc dùng từ ngữ trừu tượng để miêu tả giọng điệu mong muốn, tôi thử một lối đi khác. Nguồn cảm hứng bất ngờ đến từ trải nghiệm với Midjourney trong lĩnh vực tạo sinh hình ảnh. Tôi từng khao khát diễn tả một phong cách hình ảnh chi tiết, tinh xảo nhưng không quá phô trương, và đã loay hoay rất lâu để tìm từ ngữ diễn đạt. Rồi một chuyên gia gợi ý thử "phong cách Rococo", và kết quả thật mỹ mãn, đúng như những gì tôi hình dung. Tương tự, văn phong của Hemingway thật khó để định nghĩa một cách chính xác. Bạn có thể dùng vô số từ ngữ để mô tả đặc trưng của ông – câu văn ngắn gọn, ngôn ngữ trực diện, nghệ thuật nói giảm nói tránh – nhưng để AI hay thậm chí con người viết theo phong cách Hemingway chỉ dựa trên những mô tả ấy thì quả là một thử thách cam go. Tuy nhiên, vì AI đã "đọc" qua các tác phẩm của Hemingway trong quá trình huấn luyện, nên nếu bạn trực tiếp yêu cầu nó viết theo văn phong Hemingway, nó có thể mô phỏng khá tốt. Đây chính là sức mạnh của "bối cảnh", của "trường phái", hay thứ mà chúng ta có thể gọi là "ý niệm hình ảnh" (imagery).

Do đó, hướng tiếp cận thứ hai của tôi là cố gắng giúp AI tìm ra những khái niệm trừu tượng từ các nhà văn hoặc trường phái văn học tương đồng, với hy vọng chúng có thể giúp AI "ngộ" ra cách điều chỉnh giọng điệu. Tiếc thay, sau một thời gian làm việc cùng AI, chúng tôi không thể tìm thấy phong cách của bất kỳ nhà văn hay trường phái nào có thể nắm bắt hiệu quả văn phong của tôi. Suy cho cùng, những người lưu danh sử sách đều là bậc thầy – dùng phong cách của họ để mô phỏng một người bình thường như tôi quả thực là một yêu cầu quá sức.

Dù hướng đi này thất bại, nó cũng mang lại những tia sáng nhận thức: nếu muốn đạt được sự kiểm soát chi tiết hơn, chỉ mô tả thôi là chưa đủ – AI cần nhiều thông tin hơn. Khi đã có một khái niệm tồn tại sẵn (như "phong cách Rococo"), thông tin này có thể được cô đọng trong một từ duy nhất. Nhưng khi không có khái niệm sẵn có, có lẽ chúng ta có thể cung cấp cho nó nhiều ví dụ để học hỏi trong thời gian thực. Đây chính là phương pháp **few-shot learning (học từ một vài ví dụ)**. Cụ thể, khi giao một tác vụ dịch thuật, tôi không chỉ cung cấp văn bản gốc tiếng Anh mà còn đính kèm một vài bài viết trước đó của mình, với hy vọng AI có thể noi theo những ví dụ này để tạo ra bản dịch bớt "AI-tính".

Nhưng than ôi, phương pháp này cũng không mang lại kết quả. Sau khi suy ngẫm về nguyên nhân, tôi nhận ra rằng việc cố gắng xây dựng một phong cách hoàn chỉnh chỉ từ một vài bài viết có lẽ là một đòi hỏi quá cao. Đặc biệt khi các bài viết thuộc những lĩnh vực khác nhau, nơi mà thuật ngữ chuyên ngành và thói quen dùng từ không có tài liệu tham khảo trực tiếp, AI cuối cùng lại quay về với kho kiến thức sẵn có của nó. Và rồi, nó lại trở về với cái giọng điệu "lãnh đạo phát biểu" kia.

Nếu đây là nguyên nhân, thì việc giải quyết thực ra không quá khó. Thay vì ngẫu nhiên chọn vài bài viết làm ví dụ, chúng ta có thể thực hiện một bước truy xuất (retrieval) trên kho bài viết trước đây của mình, sau đó sử dụng những đoạn văn nhỏ có liên quan đến văn bản cần dịch làm ví dụ. Bằng cách này, chúng ta có thể đảm bảo rằng những ví dụ mà AI tiếp xúc đều liên quan mật thiết đến nội dung nó cần dịch, từ đó nâng cao đáng kể hiệu quả cung cấp tài liệu nền cho AI.

Nhưng đáng buồn thay, phương pháp này cũng chịu chung số phận. So với bản dịch "thuần AI", kết quả sử dụng phương pháp này hoặc không cho thấy sự khác biệt đáng kể, hoặc không thể đạt được sự kiểm soát tương đối tinh vi. Ngoài ra, tôi cũng đã thử nghiệm các công cụ được cung cấp bởi những sản phẩm khác, bao gồm tính năng phong cách của Claude và nhiều AI khác nhau (một ghi chú nhỏ: Gemini AI có vẻ ít "AI-tính" nhất), nhưng xét trên phương diện trừu tượng, chúng đều không vượt ra ngoài những cách tiếp cận đã mô tả ở trên, và kết quả cũng không mấy khả quan.

**Fine-tuning: Vũ Khí Giúp AI "Nội Tâm Hóa" Những Chỉnh Sửa Chính Xác**

Dù những phương pháp kể trên đều thất bại, chúng vẫn mang lại những bài học quý giá: tại sao vấn đề này lại khó khăn đến vậy? Chủ yếu là vì đây không phải là một yêu cầu rõ ràng, dễ dàng mô tả bằng ngôn ngữ. AI đã đọc vô số sách và chắc chắn đã từng tiếp xúc với kiểu văn phong giản dị, thân thiện này. Trong một số thử nghiệm trước đó, chúng ta có thể thấy rằng nó *có khả năng* nói theo phong cách của tôi – vấn đề cốt lõi là làm thế nào để chúng ta diễn đạt cho AI hiểu *chính xác* phong cách đó là gì.

Tại sao việc diễn đạt này lại khó khăn? Có hai lý do chính. Thứ nhất, nó đòi hỏi sự **chính xác cực cao**. Ví dụ, nhìn vào hai bản dịch ở trên của AI và của tôi, chúng chỉ khác biệt vài từ, nhưng giọng điệu và phong cách lại hoàn toàn khác biệt. Thứ hai, có lẽ chính vì sự chính xác này, nếu AI muốn "nội tâm hóa" những chỉnh sửa này, nó cần **rất nhiều ví dụ**, tốt nhất là bao quát nhiều chủ đề và kịch bản khác nhau. Nói cách khác, vấn đề trung tâm của chúng ta là làm thế nào để AI có thể "thẩm thấu" những chỉnh sửa và hướng dẫn rải rác, vụn vặt nhưng lại vô cùng chính xác này. Vũ khí truyền thống của chúng ta là prompting, nhưng dường như nó không đủ sức cho những nhu cầu như vậy.

**Fine-tuning Là Gì?**

Đây là lúc fine-tuning tự nhiên nổi lên như một giải pháp tiềm năng. Fine-tuning không phải là một khái niệm mới. Như chúng ta đã thảo luận trong một bài viết trước, trước khi các mô hình nền tảng (foundation models) xuất hiện, fine-tuning thực chất là phương pháp chính để sử dụng mô hình. AI hiện đại (LLM) dựa trên zero-shot learning (học không cần ví dụ) hoặc few-shot learning, sử dụng các ví dụ được cung cấp trong văn bản đầu vào để học hỏi và hiểu ý định của người dùng một cách linh hoạt trước khi tạo ra kết quả. Trong suốt quá trình này, bản thân mô hình không hề thay đổi.

Fine-tuning, ngược lại, đi một con đường hoàn toàn khác: nó đòi hỏi sự can thiệp vào chính "bộ não" của mô hình, **tinh chỉnh "nội dung" bên trong để tạo ra những thay đổi trong hành vi của nó**. Cụ thể, nó cần được "cho xem" rất nhiều dữ liệu huấn luyện, trong đó mỗi mẩu dữ liệu bao gồm một đầu vào (input) và một đầu ra mong đợi (ground truth). Thuật toán fine-tuning sẽ thay đổi nội dung (các trọng số - weights) của mô hình để khiến nó tạo ra các kết quả càng giống với kết quả mong đợi càng tốt khi nhận được các đầu vào tương ứng. Thông qua việc điều chỉnh lặp đi lặp lại các trọng số này, mô hình có thể "nội tâm hóa" thông tin mà chúng ta truyền tải qua dữ liệu huấn luyện.

Một ví dụ đơn giản: chúng ta có thể fine-tune một mô hình để xác định xem một đánh giá của khách hàng là tích cực hay tiêu cực. Ở đây, đầu vào của dữ liệu huấn luyện sẽ là chính đánh giá đó, và đầu ra sẽ là phán đoán tích cực hoặc tiêu cực. Quá trình fine-tuning mô hình là liên tục điều chỉnh các tham số của mô hình sao cho khi nó nhìn thấy mỗi đánh giá đầu vào, nó có thể đưa ra phán đoán chính xác.

Dĩ nhiên, việc phán đoán đánh giá của khách hàng chỉ là một ví dụ "đồ chơi" – AI hiện đại có thể làm tốt điều này mà không cần fine-tuning. Nhưng đối với những nhu cầu phức tạp hơn, chẳng hạn như phát hiện các bình luận mang tính công kích thụ động (passive-aggressive), fine-tuning trở thành một vũ khí lợi hại. Fine-tuning cho phép chúng ta cung cấp cho mô hình rất nhiều ví dụ, để nó cẩn thận xem xét và hiểu cách đưa ra phán đoán trong các điều kiện và kịch bản khác nhau, và sau đó "nội tâm hóa" những chỉnh sửa rải rác, chính xác này.

Tuy nhiên, việc sửa đổi chính bản thân mô hình này là một **con dao hai lưỡi**. Một mặt, nó có thể giúp mô hình tiếp nhận hiệu quả rất nhiều hướng dẫn; mặt khác, vì mô hình huấn luyện rất lớn, đây cũng là một quá trình vô cùng **nặng nề (heavyweight)**. Chúng ta cần chuẩn bị một lượng đáng kể dữ liệu huấn luyện, có thể lên đến hàng trăm hoặc hàng ngàn cặp mẫu đầu vào-đầu ra; đồng thời, chúng ta cần tải một mô hình khổng lồ vào bộ nhớ GPU và sử dụng sức mạnh tính toán GPU khổng lồ để thực hiện những thay đổi nhỏ bé cho các trọng số của mô hình.

Do đó, fine-tuning thường đòi hỏi việc dành rất nhiều thời gian cho việc thu thập và làm sạch dữ liệu, viết và gỡ lỗi mã, và cuối cùng là lượng tử hóa (quantization) và đóng gói. Trong khi đó, toàn bộ quá trình lại đầy rẫy rủi ro và sự không chắc chắn. Đặc biệt đối với các mô hình ngôn ngữ lớn, fine-tuning có thể gây ra những thay đổi rất lớn trong hành vi của mô hình. Ví dụ, nó có thể **hoàn toàn quên đi những kỹ năng hoặc kiến thức đã học trước đó (catastrophic forgetting)**; hoặc toàn bộ mô hình có thể **sụp đổ (collapse)**, trở thành một mô hình vô dụng chỉ biết nói nhảm; hoặc mô hình có thể trở nên **quá "nhiều lời" (overly talkative)**, tiếp tục xuất những nội dung có vẻ liên quan nhưng thực chất vô nghĩa sau khi đã hoàn thành nhiệm vụ.

Thêm vào đó, fine-tuning có yêu cầu phần cứng rất cao – nếu sử dụng GPU chơi game thông thường để fine-tuning, bộ nhớ thường chỉ hỗ trợ được các mô hình khoảng 1 tỷ tham số (1B). Nếu bạn muốn thực hiện fine-tuning có giá trị thực tiễn, bạn cần ít nhất bốn card đồ họa 4090, và các cụm GPU lớn hơn nhiều cũng không phải là hiếm. Vì vậy, đây là một hoạt động vô cùng nặng nề. Đó là lý do tại sao tôi đã xếp nó vào danh sách "để sau" và thử các phương pháp khác trước.

**Những Kịch Bản Phù Hợp Và Không Phù Hợp Với Fine-tuning**

Từ mục đích "nội tâm hóa những chỉnh sửa chính xác", fine-tuning tự nhiên có những kịch bản mà nó tỏa sáng và những kịch bản khác mà nó không phù hợp. **Thay đổi phong cách đầu ra của AI** là một kịch bản phổ biến để sử dụng fine-tuning. Điều này bao gồm những thứ như giọng điệu, định dạng đầu ra (ví dụ: JSON), hoặc cách sử dụng công cụ. Ví dụ, nếu tôi có 50 công cụ có sẵn và muốn AI lựa chọn giữa chúng, sử dụng công cụ phù hợp trong tình huống phù hợp.

Trong những kịch bản này, việc fine-tune mô hình AI mang lại hai lợi ích. Lợi ích đầu tiên là nó có thể đạt được **sự kiểm soát chính xác hơn** so với các phương pháp khác, thậm chí cả PUA (Prompt Utilization Architecture – kiến trúc tận dụng prompt, thế hệ tiếp theo của prompt engineering) phức tạp. Lợi ích thứ hai là nó có thể **giảm đáng kể độ dài của prompt**. Ví dụ, ngay cả khi chúng ta có thể sử dụng các ví dụ cụ thể để thay đổi giọng điệu của AI, hoặc sử dụng prompt để giải thích cho AI chức năng và cách sử dụng cụ thể của 50 công cụ đó, chúng ta vẫn cần phải xử lý và hiểu những prompt này từ đầu mỗi lần trước khi bắt đầu tạo ra kết quả. Điều này có những bất lợi đáng kể cả về chi phí lẫn thời gian phản hồi. Nhưng nếu chúng ta sử dụng fine-tuning để "nội tâm hóa" những yêu cầu này vào mô hình, chúng ta có thể sử dụng những prompt rất đơn giản để nhận được kết quả tương tự từ AI. Trong những trường hợp như vậy, cả thời gian phản hồi cho người dùng lẫn chi phí suy luận (inference cost) đều được cải thiện đáng kể. Do đó, những kịch bản này phù hợp hơn với fine-tuning.

Có một quan niệm sai lầm phổ biến về fine-tuning là nó có thể được sử dụng để **tiêm thêm kiến thức hoặc kỹ năng mới**. Điều này không chính xác. Fine-tuning giống như việc **khơi gợi và kích hoạt những khả năng hiện có của AI** – nó không thể mang lại cho AI một khả năng hoàn toàn mới. Hay những thứ như khả năng suy luận mạnh mẽ hơn và nhiều kiến thức hơn. Nếu bạn quan tâm, bạn có thể thử fine-tune một cơ sở kiến thức vào AI và so sánh nó với RAG (Retrieval Augmented Generation – Tạo sinh Tăng cường bằng Truy xuất) để xem liệu nó có thể tận dụng hiệu quả kiến thức này hay không. Tôi đã thực hiện những thí nghiệm như vậy, và kết luận là không thể. Nhưng tôi cũng tò mò về kết luận thí nghiệm của những người khác.

**Những Quyết Định Kỹ Thuật Then Chốt Trong Hành Trình Fine-tuning**

Như đã mô tả ở trên, sau khi thử nghiệm nhiều phương pháp mà không thành công, và với fine-tuning dường như là một giải pháp phù hợp, cộng thêm việc gần đây có Agentic AI như một công cụ đắc lực, tôi đã khám phá cách sử dụng Agentic AI để giúp mình hoàn thành nhiệm vụ fine-tuning này.

Dưới đây, tôi sẽ giới thiệu một số quyết định then chốt mà tôi đã đưa ra trong quá trình sử dụng fine-tuning để giải quyết vấn đề giọng điệu của AI. Như chúng ta đã đề cập trong bài viết trước về phát triển sự nghiệp, những quyết định kỹ thuật này quan trọng hơn nhiều so với việc bạn có thể viết mã nhanh đến đâu, cẩn thận đến mức nào, hay đầu tư bao nhiêu thời gian trong quá trình vận hành thực tế. Bởi vì một khi chúng ta đưa ra một quyết định sai lầm, ngay cả khi chúng ta viết mã nhanh gấp đôi, gấp ba, nếu con đường đã sai, chúng ta sẽ phải làm lại từ đầu hoàn toàn. Thời gian lãng phí này không thể bù đắp bằng việc viết mã nhanh hơn. Do đó, trước tiên chúng ta sẽ dành chút công sức để làm rõ một số khái niệm cơ bản và quyết định kỹ thuật, sau đó sẽ giới thiệu các kỹ thuật vận hành chi tiết hơn.

Chúng tôi đã đưa ra ba quyết định quan trọng ở đây:

1.  **Parameter Efficient Fine Tuning (PEFT – Tinh Chỉnh Hiệu Quả Tham Số)**
    Chúng tôi đã sử dụng một phương pháp gọi là tinh chỉnh hiệu quả tham số, cụ thể là **LoRA (Low-Rank Adaptation)**. Ý tưởng cơ bản của LoRA là thay vì thay đổi toàn bộ hàng tỷ tham số của mô hình, nó sử dụng một phép phân rã hạng thấp (low-rank decomposition) đặc biệt để giảm đáng kể số lượng tham số cần huấn luyện. Không đi sâu vào chi tiết toán học, một cách hiểu trực quan là nó tương tự như việc chèn một vài "cái nêm" vào những điểm quan trọng nhất trong mô hình, đạt được hiệu ứng đòn bẩy thông qua việc chỉ thay đổi trọng số của những "cái nêm" này để thay đổi đáng kể hành vi tổng thể của mô hình.

    Điều này làm giảm quy mô của bài toán huấn luyện mô hình xuống còn một phần trăm so với trước đây, cho phép chúng ta fine-tune hiệu quả các mô hình tương đối lớn như 3 tỷ, 7 tỷ tham số ngay cả trên GPU chơi game thông thường. Dĩ nhiên, đây vẫn là một sự đánh đổi kỹ thuật – hiệu quả của nó thường không tốt bằng fine-tuning toàn bộ, nhưng khi chúng ta không có điều kiện mua hoặc thuê một cụm GPU lớn khác, đây là một giải pháp thỏa hiệp hiệu quả.

2.  **Reverse Data Synthesis (Tổng Hợp Dữ Liệu Ngược)**
    Quyết định quan trọng thứ hai là nguồn gốc của dữ liệu huấn luyện. Để giải quyết vấn đề giọng điệu trong dịch thuật, phương pháp hoàn hảo sẽ là cung cấp nhiều văn bản ứng dụng và để những người như tôi dịch chúng sang tiếng Trung, từ đó tạo ra dữ liệu huấn luyện theo cặp để hướng dẫn quá trình huấn luyện. Nhưng fine-tuning thường cần ít nhất hàng trăm hoặc hàng ngàn điểm dữ liệu huấn luyện, và việc tôi tự tay dịch hàng trăm hoặc hàng ngàn đoạn văn sẽ quá tốn thời gian. Trong các doanh nghiệp, phương pháp phổ biến là thuê người chú thích (annotation), nhưng trong kịch bản của chúng tôi, ngoài vấn đề chi phí, từ việc viết hướng dẫn chú thích, xác định ví dụ, đến giao tiếp với người chú thích, nghiệm thu, lặp lại, v.v., bản thân việc này đã là một "hố đen" thời gian. Các doanh nghiệp lớn có thể giao cho một người hoặc thậm chí cả một đội ngũ làm việc này mà vẫn đảm bảo lợi nhuận. Nhưng đối với cá nhân chúng tôi, điều đó hoàn toàn phi thực tế.

    Do đó, về mặt dữ liệu, tôi đã trực tiếp **sử dụng LLM để tạo dữ liệu**. Cụ thể, tôi tận dụng giọng điệu dịch thuật tự nhiên của các LLM hiện tại, trước tiên trích xuất tất cả các bài blog tiếng Trung của mình làm đầu vào, sau đó yêu cầu AI dịch từng đoạn văn tự nhiên sang tiếng Anh. Bằng cách này, chúng ta có các cặp dữ liệu trong đó đầu vào là tiếng Trung và đầu ra là tiếng Anh. Sau đó, chúng tôi **đảo ngược lại**, biến tiếng Anh đã dịch thành dữ liệu đầu vào và văn bản tiếng Trung do tôi viết thành đầu ra mong đợi, từ đó dễ dàng xây dựng một lượng lớn dữ liệu huấn luyện.

    Ví dụ, nếu blog của tôi đề cập đến "提供几个不同的API，让客户端可以提交一个新任务，然后返回一个任务的ID", câu này dịch sang tiếng Anh là "Offered several different APIs. This would allow the client to submit a new task and receive a task ID in return". Sau đó, chúng tôi lấy đoạn tiếng Anh này làm đầu vào và yêu cầu chương trình fine-tuning điều chỉnh các tham số của mô hình này sao cho đầu ra của nó càng giống với đoạn văn tiếng Trung do tôi viết càng tốt. Thông qua phương pháp này, chúng tôi đã thu được rất nhiều dữ liệu huấn luyện.

3.  **Using Commercial APIs for Opportunity Sizing (Sử Dụng API Thương Mại để "Đo Lường Cơ Hội")**
    Quyết định kỹ thuật thứ ba của tôi là **"Đo lường Cơ hội" (Opportunity Sizing)**. Như chúng ta đã đề cập trước đó, bản thân fine-tuning là một hoạt động rất nặng nề, đòi hỏi nhiều nỗ lực và có nguy cơ thất bại cao. Do đó, trước khi chúng ta cam kết đầu tư nhiều công sức nhất, chúng ta cần "thăm dò" trước để xem liệu phương pháp này có chút hy vọng thành công nào không. Xét đến chi phí cao của việc viết mã và thuê cụm máy chủ, tôi đã trực tiếp sử dụng API fine-tuning của OpenAI để "Đo lường Cơ hội".

    Cụ thể, tôi đã chọn một phần nhỏ dữ liệu huấn luyện, truy cập trang web của OpenAI và thử nghiệm tính năng fine-tuning của GPT-4o trước. Năm mươi điểm dữ liệu huấn luyện tốn ba đô la, nhưng từ mô hình trả về, nó đã phần nào đạt được sự kiểm soát về giọng điệu, ít "vị AI" hơn so với GPT-4o gốc. Do đó, tôi tiếp tục tăng cường đầu tư, sử dụng nhiều dữ liệu huấn luyện hơn để xác minh trên quy mô lớn hơn. Kết quả khá đáng khích lệ – với một số ví dụ và cài đặt tham số suy luận nhất định, nó có thể đạt được kết quả khá tốt, đôi khi tôi thậm chí còn nghĩ rằng câu đó thực sự do mình viết. Nhưng với các ví dụ khác, hiệu quả của nó vẫn chưa đạt yêu cầu, đôi khi còn gặp phải tình trạng sụp đổ. Và toàn bộ quá trình khá tốn kém – ngay cả việc fine-tune trên một tập con dữ liệu huấn luyện cũng đã tiêu tốn của tôi một trăm đô la.

    Vì vậy, thông qua việc sử dụng API của OpenAI, tôi đã tạm thời tránh được sự tẻ nhạt của việc gỡ lỗi mã và thuê cơ sở hạ tầng, xác minh thông qua một phương pháp triển khai chắc chắn đúng rằng hướng đi này có triển vọng. Nhưng đồng thời, vì nó thực sự quá đắt đỏ, điều đó cũng khiến tôi quyết tâm không tiếp tục sử dụng GPT-4o để fine-tuning, mà thay vào đó sử dụng các mô hình mã nguồn mở để giảm chi phí đồng thời đạt được sự linh hoạt cao hơn. Suy cho cùng, API của OpenAI chưa để lộ tất cả các cài đặt tham số liên quan đến fine-tuning, và có thể trong nhu cầu của chúng tôi, để cải thiện hiệu quả fine-tuning, chúng tôi cần điều chỉnh những tham số chưa được hé lộ đó.

**Sợi Chỉ Đỏ Xuyên Suốt: Hạ Thấp Rào Cản**

Ba quyết định này có một sợi chỉ đỏ xuyên suốt rất rõ ràng: **hạ thấp rào cản (lowering barriers)**.

Toàn bộ quy trình ra quyết định kỹ thuật diễn ra như sau: đầu tiên, chúng tôi sử dụng LoRA để giải quyết vấn đề rào cản sức mạnh tính toán quá cao; sử dụng dữ liệu bán tổng hợp từ AI để giải quyết vấn đề rào cản dữ liệu quá lớn; sử dụng API của OpenAI để giải quyết vấn đề rào cản về tính đúng đắn của việc triển khai, xác nhận tính khả thi của hướng đi này với chi phí 100 đô la, và đưa ra quyết định: chúng ta cần đầu tư nhiều công sức hơn vào việc fine-tune trên dữ liệu gốc. Dưới đây, chúng tôi sẽ giới thiệu cụ thể những kỹ thuật đã sử dụng trong quá trình thực thi thực tế để biến dự án vô cùng phức tạp này thành hiện thực trong vòng vài giờ.

**Chi Tiết Triển Khai Fine-tuning: Những Bài Học Xương Máu**

Quá trình triển khai fine-tuning tương đối trực quan với sự trợ giúp của Agentic AI – về cơ bản chỉ cần mô tả cho Cursor những gì bạn muốn làm. Nhưng cũng có một số cạm bẫy. Dưới đây là một vài bài học kinh nghiệm.

*   **Triển Khai Phần Cứng:**
    Có hai phương pháp chính để triển khai fine-tuning: một là sử dụng các dịch vụ như API fine-tuning của OpenAI. Lý do API của OpenAI đắt đỏ chủ yếu là vì GPT-4o là một mô hình đặc biệt lớn. Nhưng nếu chúng ta muốn fine-tune trực tiếp các mô hình mã nguồn mở, dù là AWS hay AnyScale, đều có nhiều API tương tự và chúng rẻ hơn nhiều so với việc fine-tune GPT. Hơn nữa, vì các mô hình là mã nguồn mở, chúng ta cũng có thể thực hiện nhiều tùy chỉnh.

    Phương pháp thứ hai là thuê trực tiếp một máy hoặc cụm máy GPU – điều này hoàn toàn giống như thuê một máy ảo trực tuyến, điểm khác biệt duy nhất là máy này có GPU, vì vậy chúng ta có thể tùy chỉnh hoàn toàn, làm bất cứ điều gì mình muốn.

    Trong kịch bản của tôi, vì muốn khám phá ưu nhược điểm của fine-tuning theo nhiều cách, tôi đã sử dụng phương pháp thứ hai. Cụ thể, tôi đã thuê một NVIDIA GH200 trên Lambda Labs. Gần đây họ có chương trình khuyến mãi chỉ 1.8 đô la mỗi giờ, rất hiệu quả về chi phí cho một máy có CPU 64 lõi + bộ nhớ 520GB + bộ nhớ GPU H100 96GB. Nhìn chung trải nghiệm rất tốt, nhưng điểm trừ duy nhất là CPU của nó thực sự yếu so với CPU máy chủ truyền thống, vì vậy cần một số tối ưu hóa bổ sung, chẳng hạn như sử dụng nhiều lõi để xử lý dữ liệu nhằm đảm bảo CPU không phải là điểm nghẽn và để GPU được tận dụng tối đa.

*   **Quản Lý Tài Liệu (Document Management):**
    Fine-tuning là một dự án rất phức tạp – ví dụ, chương trình cốt lõi của phiên bản fine-tuning cuối cùng của tôi có tám hoặc chín trăm dòng. Do đó, nếu chúng ta vẫn vô tư sử dụng Cursor để viết chương trình như trước, chúng ta thường rơi vào tình trạng luẩn quẩn. Ví dụ, nó đã sửa một lỗi trước đó dưới sự hướng dẫn và chỉnh sửa của chúng ta, nhưng sau nhiều vòng đối thoại, có thể do lần sửa trước đó nằm ngoài cửa sổ ngữ cảnh (context window) của vòng đối thoại mới nhất, nó đã mất đi kiến thức nền này và thay đổi lại trong vòng thay đổi mới. Đây là một kiểu thất bại điển hình khi sử dụng Cursor cho việc triển khai các dự án kỹ thuật quy mô lớn.

    Giải quyết vấn đề này đòi hỏi **Quản Lý Tài Liệu** mà chúng ta đã đề cập trước đó – tức là, sau khi nó sửa một lỗi, chúng ta có thể sử dụng prompt để yêu cầu nó ghi lại những kinh nghiệm mới học được vào `.cursorrules`, để yêu cầu này trở thành một phần của prompt được gửi đến AI mỗi lần, và nó sẽ không mắc lại lỗi này trong tương lai. Nhưng với việc phát hành phiên bản 0.44 mới nhất của Cursor, tôi thấy nó ngày càng trở nên kém nhạy cảm với chỉ dẫn này. Vì vậy, nếu cần, việc tự tay yêu cầu nó tóm tắt kinh nghiệm một cách rõ ràng vẫn đáng tin cậy hơn. Ngoài ra, việc yêu cầu nó duy trì một kế hoạch tổng thể và tiến độ hiện tại trong `.cursorrules` cũng là một cách hiệu quả để ngăn nó bắt đầu bận rộn với một việc không liên quan khác giữa chừng.

    Nhìn chung, trong quá trình sử dụng Agentic AI để lập trình, vai trò của chúng ta giống như một người quản lý phát triển, với trách nhiệm chính là đánh giá hiệu quả phát triển, hướng dẫn định hướng phát triển, và đồng bộ hóa tiến độ phát triển, đồng thời truyền cảm hứng cho AI ghi chú một cách phù hợp để nó cũng có thể trưởng thành. Một điểm thú vị là trong bài viết này giới thiệu về fine-tuning, tôi hoàn toàn không đề cập đến việc chúng ta cần sử dụng thư viện hay framework nào. Điều này là bởi vì bây giờ tất cả những thứ đó đều do Agentic AI xử lý – chúng ta không cần phải quan tâm đến chúng. Năng lượng của chúng ta nên được dành cho việc đưa ra các quyết định như "có nên sử dụng fine-tuning hay không" và các quyết định then chốt khác đã đề cập ở trên.

*   **Nhiều Tác Vụ Phụ Trợ Hơn:**
    Sau khi sử dụng Agentic AI để thực hiện tác vụ fine-tuning cốt lõi, chúng ta cũng có thể yêu cầu nó thực hiện thêm các Unit Test, cũng như công việc lượng tử hóa, trực quan hóa và suy luận. Ví dụ, kết hợp với công cụ dữ liệu (data engine), chúng ta có thể yêu cầu nó trước tiên hợp nhất mô hình định dạng Hugging Face được tạo ra từ quá trình huấn luyện với mô hình LoRA, sau đó sử dụng `llama.cpp` để lượng tử hóa và suy luận trên Mac. Ngoài ra, chúng ta có thể yêu cầu nó tạo ra các so sánh với các mô hình thương mại – ví dụ, trang web này trình bày sự so sánh giữa GPT-4o và các mô hình Qwen 2.5 3B và 7B đã được tôi fine-tune.

    *(Hình ảnh ví dụ kết quả fine-tune được mô tả trong văn bản gốc)*

    Trên đây là một ví dụ cụ thể – chúng ta có thể thấy rằng khả năng nắm bắt giọng điệu của mô hình đã được fine-tune khá chính xác, thường rất gần với câu trả lời tham khảo.

**Lời Kết: Hành Trình Gian Nan Nhưng Xứng Đáng**

Tóm lại, chúng ta đã giải quyết được bài toán khó khăn về việc kiểm soát chính xác giọng điệu của AI thông qua fine-tuning. Trong suốt hành trình này, có một vài điểm cần nhắc nhở mọi người.

Fine-tuning là một công nghệ với sự linh hoạt tuyệt vời, nhưng cũng đi kèm với những hạn chế và rủi ro đáng kể. Trước khi sử dụng fine-tuning, chúng ta thường thử nghiệm nhiều phương pháp nhẹ nhàng hơn trước, sau đó mới đi theo con đường fine-tuning. Và ngay cả trước khi thực sự fine-tune, chúng ta cũng sẽ sử dụng các API đã trưởng thành để "đo lường cơ hội" nhằm tránh lãng phí thời gian và kiểm soát rủi ro.

Nhưng tin tốt là ngay cả đối với người tiêu dùng bình thường, fine-tuning giờ đây đã là một vũ khí có thể tiếp cận. Về mặt thuật toán, chúng ta có thể sử dụng các thuật toán tiết kiệm bộ nhớ như LoRA. Về dữ liệu, chúng ta có thể sử dụng LLM để tạo dữ liệu. Và về phần cứng, chúng ta có thể thuê các API hoặc phần cứng sẵn có từ các nhà cung cấp dịch vụ đám mây.

Ngay cả với những kỹ thuật này, fine-tuning vẫn là một thử thách không nhỏ đối với Agentic AI. Do đó, trong quá trình này, chúng ta cần đặc biệt cẩn thận để yêu cầu AI duy trì một tài liệu từ đầu đến cuối, tóm tắt kế hoạch mục tiêu của chúng ta và những kinh nghiệm đã học được của nó trên đó. Điều này có thể cải thiện đáng kể hiệu quả làm việc của AI và tránh rơi vào cái bẫy lặp đi lặp lại cùng một sai lầm.

Hành trình thuần hóa AI để nó "giống mình" hơn, dù gian nan, nhưng những thành quả đạt được, dù là nhỏ nhất, cũng mang lại niềm vui khám phá và sự thấu hiểu sâu sắc hơn về thế giới phức tạp và đầy tiềm năng của trí tuệ nhân tạo.
